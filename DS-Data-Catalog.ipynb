{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6474f65c-a0da-4e64-9251-439f77d8d5a7",
   "metadata": {},
   "source": [
    "# Data Catalog of DS-Students-Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc3f3fd0-a124-4a42-9e78-df00fe2640af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd01b26b-c343-4fec-9354-9f850e326c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to recursively find all dataset files in local GitHub repository\n",
    "def find_datasets(root_path, extensions):\n",
    "    datasets = []\n",
    "    for ext in extensions:\n",
    "        datasets.extend([path for path in Path(root_path).rglob(f\"*.{ext}\") if \".ipynb_checkpoints\" not in str(path)])\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c37eb7-1553-4d03-93ee-aced669b5715",
   "metadata": {},
   "source": [
    "### List (not exhaustive) of dataset file formats and their corresponding extensions:\n",
    "\n",
    "- CSV (Comma Separated Values): csv\n",
    "- TSV (Tab Separated Values): tsv\n",
    "- JSON (JavaScript Object Notation): json\n",
    "- Excel: xls, xlsx\n",
    "- Plain Text: txt\n",
    "- Data: data\n",
    "- HDF5 (Hierarchical Data Format): h5, hdf5\n",
    "- NetCDF (Network Common Data Form): nc, nc4\n",
    "- XML (eXtensible Markup Language): xml\n",
    "- Parquet: parquet\n",
    "- Avro: avro\n",
    "- Feather: feather\n",
    "- ORC (Optimized Row Columnar): orc\n",
    "- Protocol Buffers: pb, pbf\n",
    "- GeoJSON: geojson\n",
    "- Pickle: pkl, pickle\n",
    "- MATLAB: mat\n",
    "- ARFF (Attribute-Relation File Format): arff\n",
    "- NPY (NumPy array): npy\n",
    "- NPZ (NumPy Zipped): npz\n",
    "- SAS: sas7bdat\n",
    "- STATA: dta\n",
    "- R (RData, RDS): RData, rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb09a50a-ce18-4530-ade4-358f5b2595ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the extensions of dataset files you want to search for and call the find_datasets function.\n",
    "dataset_extensions = [\n",
    "    \"csv\", \"tsv\", \"json\", \"xlsx\", \"xls\", \"txt\", \"data\", \"h5\", \"hdf5\",\n",
    "    \"nc\", \"nc4\", \"xml\", \"parquet\", \"avro\", \"feather\", \"orc\", \"pb\", \"pbf\",\n",
    "    \"geojson\", \"pkl\", \"pickle\", \"mat\", \"arff\", \"npy\", \"npz\", \"sas7bdat\",\n",
    "    \"dta\", \"RData\", \"rds\"\n",
    "]\n",
    "\n",
    "root_dir = \".\"  # The root directory of local GitHub repository\n",
    "datasets = find_datasets(root_dir, dataset_extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d039f312-1a7b-4adc-9354-2bb6375c2801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to extract the necessary metadata from each dataset file.\n",
    "def get_dataset_metadata(dataset_path):\n",
    "    metadata = {\n",
    "        \"filename\": dataset_path.name,\n",
    "        \"path\": str(dataset_path),\n",
    "        \"extension\": dataset_path.suffix[1:],\n",
    "        \"size\": dataset_path.stat().st_size,\n",
    "        \"mime_type\": mimetypes.guess_type(dataset_path)[0] or \"unknown\",\n",
    "        \"modified_date\": datetime.fromtimestamp(dataset_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e86e374a-ece4-43ec-bb61-e442f1fc3f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to store the dataset metadata and write it to a CSV file.\n",
    "dataset_metadata = [get_dataset_metadata(ds) for ds in datasets]\n",
    "metadata_df = pd.DataFrame(dataset_metadata)\n",
    "metadata_df.to_csv(\"ds-datasets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba5fcde9-4063-482c-91f3-6c65e88c8d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=bbdac616-36f6-4dd2-8a29-89cd8565f90a style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('bbdac616-36f6-4dd2-8a29-89cd8565f90a').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>extension</th>\n",
       "      <th>size</th>\n",
       "      <th>mime_type</th>\n",
       "      <th>modified_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ds-video-catalog.csv</td>\n",
       "      <td>ds-video-catalog.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>58324</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>2023-04-06 12:55:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ds-datasets.csv</td>\n",
       "      <td>ds-datasets.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>62323</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>2023-04-06 12:56:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ds-jupyter-notebooks.csv</td>\n",
       "      <td>ds-jupyter-notebooks.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>96083</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>2023-04-06 12:54:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS-Students.csv</td>\n",
       "      <td>DS108-Databases/NoSQL/Data/DS-Students.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>12452</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>2021-11-18 13:17:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addresses.csv</td>\n",
       "      <td>DS108-Databases/SQL/Workshops/Week-2/08-Export-to-CSV/addresses.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>52009</td>\n",
       "      <td>text/csv</td>\n",
       "      <td>2021-12-03 16:18:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                   filename  \\\n",
       "0      ds-video-catalog.csv   \n",
       "1           ds-datasets.csv   \n",
       "2  ds-jupyter-notebooks.csv   \n",
       "3           DS-Students.csv   \n",
       "4             addresses.csv   \n",
       "\n",
       "                                                path extension   size  \\\n",
       "0                               ds-video-catalog.csv       csv  58324   \n",
       "1                                    ds-datasets.csv       csv  62323   \n",
       "2                           ds-jupyter-notebooks.csv       csv  96083   \n",
       "3         DS108-Databases/NoSQL/Data/DS-Students.csv       csv  12452   \n",
       "4  DS108-Databases/SQL/Workshops/Week-2/08-Export...       csv  52009   \n",
       "\n",
       "  mime_type        modified_date  \n",
       "0  text/csv  2023-04-06 12:55:17  \n",
       "1  text/csv  2023-04-06 12:56:08  \n",
       "2  text/csv  2023-04-06 12:54:27  \n",
       "3  text/csv  2021-11-18 13:17:16  \n",
       "4  text/csv  2021-12-03 16:18:53  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the metadata contained in the metadata_df\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecdbe98d-1b1c-4951-9cf4-530cf0d55345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of all Datasets: 918.72 MB\n"
     ]
    }
   ],
   "source": [
    "# computer and print total size of all datasets\n",
    "total_size_bytes = metadata_df[\"size\"].sum()\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)  # Convert bytes to megabytes\n",
    "print(f\"Total size of all Datasets: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10c3d906-e3f7-412b-86d9-4c5f0815f8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Datasets: 482\n"
     ]
    }
   ],
   "source": [
    "# count total number of datasets\n",
    "total_datasets = len(datasets)\n",
    "print(f\"Total number of Datasets: {total_datasets}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
