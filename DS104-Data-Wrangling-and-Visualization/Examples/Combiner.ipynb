{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b377c68d-5a70-4c47-924f-4c5050ba0a8d",
   "metadata": {},
   "source": [
    "# combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016672e-811e-4208-90fc-503c3de4721e",
   "metadata": {},
   "source": [
    "There are several ways to combine multiple CSV files in multiple folders. \n",
    "\n",
    "Here are a few options:\n",
    "\n",
    "- Using the command line: You can use the “cat” command to concatenate all of the CSV files in a given directory and its subdirectories. For example, to combine all CSV files in the current directory and its subdirectories, you would use the command: “cat **/*.csv > combined.csv”\n",
    "- Using Python: You can use the pandas library in Python to read in multiple CSV files and concatenate them into a single DataFrame. You can then export the DataFrame to a new CSV file.\n",
    "- Using R: You can use the read.csv() function in R to read in multiple CSV files and bind them together using the rbind() function. You can then write the combined data frame into a new csv using write.csv()\n",
    "- Using Excel or Google Sheets: You can open each CSV file in Excel or Google Sheets and copy and paste the data into a new sheet or workbook. Then you can save the combined data as a new CSV file.\n",
    "\n",
    "It depends on your skill set, knowledge and the size of your files which options would be the best.\n",
    "\n",
    "You can use the pandas library in Python to combine multiple CSV files in multiple folders. Here is an example of how you can do this:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "path = '/Combiner_Files'  # replace with the path to the folder containing the source CSV files\n",
    "all_files = os.listdir(path)\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    full_path = os.path.join(path, file)\n",
    "    df = pd.read_csv(full_path)\n",
    "    df_list.append(df)\n",
    "combined_df = pd.concat(df_list)\n",
    "combined_df.to_csv('combined.csv', index=False)\n",
    "```\n",
    "\n",
    "This code will go through all the csv files in the folder, read them into dataframe and then concatenate them into a single DataFrame. The resulting DataFrame is then saved to a new CSV file called “combined.csv” in the same directory.\n",
    "\n",
    "You can also use the glob library to find all the csv files in subfolders recursively and replace the \n",
    "\n",
    "```python\n",
    "os.listdir(path) \n",
    "```\n",
    "\n",
    "with \n",
    "\n",
    "```python\n",
    "glob.glob(path + '/**/*.csv', recursive=True)\n",
    "```\n",
    "\n",
    "Please note that you need to replace /path/to/folder in the code above with the actual path to the folder containing the CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7239f0-aa14-45ee-bca6-2d192a1ca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = 'Combiner_Files'  # replace with the path to the folder containing the source CSV files\n",
    "all_files = os.listdir(path)\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    full_path = os.path.join(path, file)\n",
    "    df = pd.read_csv(full_path)\n",
    "    df_list.append(df)\n",
    "combined_df = pd.concat(df_list)\n",
    "combined_df.to_csv('Combiner_Files/combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d2882-1342-4ecf-9912-7026186836c5",
   "metadata": {},
   "source": [
    "###  Notice that you have combined the files but isn't really what we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83150a59-57d3-4d81-aff6-8314c5f0df47",
   "metadata": {},
   "source": [
    "You can use the pd.concat() function in pandas to combine two files, each with specified columns. Here’s an example of how you can do this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read the first file into a DataFrame and select specific columns\n",
    "df1 = pd.read_csv('file1.csv', usecols=['column1', 'column2'])\n",
    "\n",
    "# Read the second file into a DataFrame and select specific columns\n",
    "df2 = pd.read_csv('file2.csv', usecols=['column3', 'column4'])\n",
    "\n",
    "# Combine the two DataFrames using pd.concat\n",
    "combined_df = pd.concat([df1, df2], axis=1)\n",
    "print(combined_df)\n",
    "```\n",
    "\n",
    "In this example, the pd.read_csv() function is used to read the first file and select only the columns ‘column1’ and ‘column2’, and the second file and select only the columns ‘column3’ and ‘column4’. Then the pd.concat() function is used to combine the two DataFrames along the columns (axis=1) and the resulting DataFrame contains the data from both files and only the columns specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f49964-1420-4a26-a0c7-de2bc4e5ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first file into a DataFrame and select specific columns\n",
    "df1 = pd.read_csv('Combiner_Files/file1.csv', usecols=['uniqueID', 'FirstName', 'LastName'])\n",
    "\n",
    "# Read the second file into a DataFrame and select specific columns\n",
    "df2 = pd.read_csv('Combiner_Files/file2.csv', usecols=['StreetNumber', 'StreetName', 'TownCity', 'State'])\n",
    "\n",
    "# Combine the two DataFrames using pd.concat\n",
    "combined_df = pd.concat([df1, df2], axis=1)\n",
    "combined_df.to_csv('Combiner_Files/combined2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8a9b2-74fa-4f2f-842e-1b6c69dcc21d",
   "metadata": {},
   "source": [
    "### This gets very close to what we wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05a072-b75a-452d-95ef-9a565a08bccc",
   "metadata": {},
   "source": [
    "You can also use the merge function to merge the two files based on a common column\n",
    "\n",
    "```python\n",
    "combined_df = pd.merge(df1, df2, on='common_column') \n",
    "```\n",
    "\n",
    "This will merge the two dataframe on the column ‘common_column’ and the resulting DataFrame will contain the data from both files and only the columns specified in both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2e1e50-fa5c-46f7-b759-4734db313c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Read the first file into a DataFrame \n",
    "df1 = pd.read_csv('Combiner_Files/file1.csv')\n",
    "\n",
    "# Read the second file into a DataFrame \n",
    "df2 = pd.read_csv('Combiner_Files/file2.csv')\n",
    "\n",
    "# Combine the two DataFrames using pd.merge and use 'uniqueID'\n",
    "combined_df = pd.merge(df1, df2, on='uniqueID') \n",
    "combined_df.to_csv('Combiner_Files/combined3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5c68b-8fac-431f-ac40-e1781898383b",
   "metadata": {},
   "source": [
    "### This does the combine a little bit more eloquently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ab62a5-ad44-4e96-a371-dff3bcd2af41",
   "metadata": {},
   "source": [
    "Say you had to different named files and you just wanted to bring a specific file in and specific columns\n",
    "\n",
    "You can use the glob module in Python to find files that match a specific pattern and then use regular expressions (regex) to identify the specific files you want to use as Name.csv and Address.csv.\n",
    "\n",
    "Here’s an example of how you can do this:\n",
    "\n",
    "```python\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Use glob to find all files that match a specific pattern\n",
    "files = glob.glob('Combiner_Files/*.csv')\n",
    "\n",
    "# Use a regular expression to identify the specific files you want to use\n",
    "name_file = next(f for f in files if re.search(r'Name', f))\n",
    "address_file = next(f for f in files if re.search(r'Address', f))\n",
    "\n",
    "# Read the files into DataFrames\n",
    "df_name = pd.read_csv(name_file)\n",
    "df_address = pd.read_csv(address_file)\n",
    "\n",
    "# Perform operations on the DataFrames\n",
    "...\n",
    "```\n",
    "\n",
    "In this example, the glob.glob() function is used to find all .csv files in the path/to/files/ directory. Then, the next() function is used in conjunction with a regular expression to identify the specific file with the name Name and Address and assign it to the variable name_file and address_file respectively. Finally, the two files are read into DataFrames using the pd.read_csv() function.\n",
    "\n",
    "You can also use the re.search() function to find a file that matches a specific pattern. For example, if the files are named as ‘file1-Name.csv’ and ‘file2-Address.csv’ you can use\n",
    "\n",
    "```python\n",
    "name_file = next(f for f in files if re.search(r'Name_2023_01_01', f))\n",
    "address_file = next(f for f in files if re.search(r'Address_2023_01_01', f))\n",
    "```\n",
    "\n",
    "This will assign the Name_2023_01_01.csv and Address_2023_01_01.csv to the variables name_file and address_file respectively.\n",
    "\n",
    "It’s worth noting that, if the files are not present in the directory or the pattern is not matching any files, this will raise a StopIteration exception. You should handle this exception in your code, for example by using a try-except block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11fe9c10-2298-434a-9989-9ab6a7b512d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "# Use glob to find all files that match a specific pattern\n",
    "files = glob.glob('Combiner_Files/*.csv')\n",
    "\n",
    "# Use a regular expression to identify the specific files you want to use\n",
    "name_file = next(f for f in files if re.search(r'Name', f))\n",
    "address_file = next(f for f in files if re.search(r'Address', f))\n",
    "\n",
    "# Read the files into DataFrames\n",
    "df_name = pd.read_csv(name_file)\n",
    "df_address = pd.read_csv(address_file)\n",
    "\n",
    "# Combine the two DataFrames using pd.merge and use 'uniqueID'\n",
    "combined_df = pd.merge(df_name, df_address, on='uniqueID') \n",
    "combined_df.to_csv('Combiner_Files/combined-Name-Address.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0db91-2809-4373-aeee-a89df0e4c554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
